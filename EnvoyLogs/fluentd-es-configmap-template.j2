kind: ConfigMap
apiVersion: v1
metadata:
  name: fluentd-es-config
  namespace: kube-system
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
data:
  system.conf: |-
    <system>
      root_dir /tmp/fluentd-buffers/
    </system>

  containers.input.conf: |-
    # Json Log Example:
    # {"log":"[info:2019-02-16T16:04:05.930-08:00] Some log text here\n","stream":"stdout","time":"2019-02-17T00:04:05.931087621Z"}
    # CRI Log Example:
    # 2019-02-17T00:04:05.931087621Z stdout F [info:2019-02-16T16:04:05.930-08:00] Some log text here
    <source>
      @id fluentd-containers.log
      @type tail
      path /var/log/containers/*.log
      pos_file /var/log/es-containers.log.pos
      tag raw.kubernetes.*
      read_from_head true
      <parse>
        @type multi_format
        <pattern>
          format json
          time_key time
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </pattern>
        <pattern>
          format /^(?<time>.+) (?<stream>stdout|stderr) [^ ]* (?<log>.*)$/
          time_format %Y-%m-%dT%H:%M:%S.%N%:z
        </pattern>
      </parse>
    </source>

    # Detect exceptions in the log output and forward them as one log entry.
    <match raw.kubernetes.**>
      @id raw.kubernetes
      @type detect_exceptions
      remove_tag_prefix raw
      message log
      stream stream
      multiline_flush_interval 5
      max_bytes 500000
      max_lines 1000
    </match>

  forward.input.conf: |-
    # Takes the messages sent over TCP
    <source>
      @type forward
    </source>


  output.conf: |-
    <match kubernetes.var.log.containers.**kube-system**.log>
      @type null
    </match>

    # Enriches records with Kubernetes metadata
    <filter kubernetes.**>
      @type kubernetes_metadata
    </filter>

    # Enriches records with my own istio-proxy format
    <filter **_istio-proxy-**>
      @type parser
      key_name log
      reserve_data true
      <parse>
        @type multi_format
        <pattern>
          format /\[(?<time>[^\]]*)\] "(?<iproxy_method>[^ ]*) (?<iproxy_path>[^ ]*) (?<iproxy_protocol>[^"]*)" (?<iproxy_response_code>[^ ]*) (?<iproxy_response_flags>[^ ]*) "(?<iproxy_mixer-code>[^ ]*)" "(?<iproxy_mixer-code2>[^ ]*)" (?<iproxy_bytes_received>[^ ]*) (?<iproxy_bytes_sent>[^ ]*) (?<iproxy_duration>[^ ]*) (?<iproxy_upstream_service_time>[^ ]*) "(?<iproxy_real_ip>[^\]]*)" "(?<iproxy_user-agent>[^\]]*)" "(?<iproxy_request_id>[^ ]*)" "(?<iproxy_authority>[^ ]*)" "(?<iproxy_upstream_host>[^ ]*)" (?<iproxy_cluster>[^ ]*) (?<iproxy_local>[^ ]*) (?<iproxy_downstream-local>[^ ]*) (?<iproxy_downstream-remote>[^ ]*) (?<iproxy_requested-server>[^ ]*)/
          time_format %Y-%m-%dT%H:%M:%S.%LZ
          types iproxy_response_code:integer,iproxy_duration:integer
        </pattern>
        <pattern>
          format /^(?<keepmessage>.*)$/
        </pattern>
      </parse>
    </filter>

    <match **>
      @id elasticsearch
      @type elasticsearch
      @log_level info
      type_name fluentd
      include_tag_key true
      host elasticsearch-logging
      port 9200
      logstash_format true
      flush_interval 1s
      <buffer>
        @type file
        path /var/log/fluentd-buffers/kubernetes.system.buffer
        flush_mode interval
        retry_type exponential_backoff
        flush_thread_count 4
        flush_interval 2s
        retry_forever
        retry_max_interval 30
        chunk_limit_size 2M
        queue_limit_length 64
        overflow_action block
      </buffer>
    </match>
